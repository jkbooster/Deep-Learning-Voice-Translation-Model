# -*- coding: utf-8 -*-
"""VoiceTranslationModel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gwXHi2YZ9W0n0iu-X9Gy5fpvmJDJBcKI
"""

import gradio as gr
import assemblyai as aai
import uuid
import os
from googletrans import Translator
from elevenlabs import VoiceSettings
from elevenlabs.client import ElevenLabs
from pathlib import Path

def voice(audio_file, lang_code):
  transcript = transcription(audio_file)
  if transcript.status == aai.TranscriptStatus.error:
      raise gr.Error(transcript.error)

  text = transcript.text

  translated_text = translation(text, lang_code)
  audio_path = text_to_speech(translated_text)
  return Path(audio_path)

def transcription(audio_file):
  aai.settings.api_key = "34de83e8b6484c29909180336ee9f68d"
  transcriber = aai.Transcriber()
  trans = transcriber.transcribe(audio_file)
  return trans

def translation(text, target_lang):
    translator = Translator()
    translated = translator.translate(text, dest=target_lang)
    print(f"Translated ({target_lang}):", translated.text)
    return translated.text

def text_to_speech(text):
  elevenlabs = ElevenLabs(api_key="2038a6c14e20f0d471e4167b04b3a8bf36123a8fd2f588077cd2654ac1f8a013")

  response = elevenlabs.text_to_speech.convert(voice_id="pNInz6obpgDQGcFmaJgB", output_format="mp3_22050_32", text=text,
                                               model_id="eleven_multilingual_v2", voice_settings=VoiceSettings(stability=0.0, similarity_boost=0.75,
                                                                                                          style=0.4, use_speaker_boost=True, speed=1.0,),)

  save_file_path = f"{uuid.uuid4()}.mp3"
  with open(save_file_path, "wb") as f:
      for chunk in response:
          if chunk:
              f.write(chunk)

  print(f"{save_file_path}: A new audio file was saved successfully!")
  return save_file_path

language_dropdown = gr.Dropdown(label="Target Language", choices=["es", "ja", "it", "fr", "de", "zh", "hi", "ar"], value="es")
input_audio = gr.Audio(sources=["microphone"], type="filepath")
demo = gr.Interface(fn=voice, inputs=[input_audio, language_dropdown], outputs=gr.Audio(label="Translated Audio"))

if __name__ == '__main__':
  demo.launch()





















